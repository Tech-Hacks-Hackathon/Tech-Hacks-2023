{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd9436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D, add, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb010a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"C:/Users/Chakradhar Rao/Desktop/New folder/Image Super Resolution - Unsplash\"\n",
    "hires_folder = os.path.join(base_directory, 'high res')\n",
    "lowres_folder = os.path.join(base_directory, 'low res')\n",
    "\n",
    "data = pd.read_csv(\"C:/Users/Chakradhar Rao/Desktop/New folder/Image Super Resolution - Unsplash/image_data.csv\")\n",
    "\n",
    "data['low_res']=data['low_res'].apply(lambda x: os.path.join(lowres_folder, x)).tolist()\n",
    "data['high_res']=data['high_res'].apply(lambda x: os.path.join(hires_folder, x)).tolist()\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa60ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "image_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.15)\n",
    "mask_datagen = ImageDataGenerator(rescale=1./255,validation_split=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf9010",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hiresimage_generator = image_datagen.flow_from_dataframe(\n",
    "        data,\n",
    "        x_col='high_res',\n",
    "        target_size=(800, 1200),\n",
    "        class_mode = None,\n",
    "        batch_size = batch_size,\n",
    "        seed=42,\n",
    "        subset='training')\n",
    "\n",
    "train_lowresimage_generator = image_datagen.flow_from_dataframe(\n",
    "        data,\n",
    "        x_col='low_res',\n",
    "        target_size=(800, 1200),\n",
    "        class_mode = None,\n",
    "        batch_size = batch_size,\n",
    "        seed=42,\n",
    "        subset='training')\n",
    "\n",
    "val_hiresimage_generator = image_datagen.flow_from_dataframe(\n",
    "        data,\n",
    "        x_col='high_res',\n",
    "        target_size=(800, 1200),\n",
    "        class_mode = None,\n",
    "        batch_size = batch_size,\n",
    "        seed=42,\n",
    "        subset='validation')\n",
    "\n",
    "val_lowresimage_generator = image_datagen.flow_from_dataframe(\n",
    "        data,\n",
    "        x_col='low_res',\n",
    "        target_size=(800, 1200),\n",
    "        class_mode = None,\n",
    "        batch_size = batch_size,\n",
    "        seed=42,\n",
    "        subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec986784",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(train_lowresimage_generator, train_hiresimage_generator)\n",
    "val_generator = zip(val_lowresimage_generator, val_hiresimage_generator)\n",
    "train_samples = train_hiresimage_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e968c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageGenerator(train_generator):\n",
    "    for (low_res, hi_res) in train_generator:\n",
    "            yield (low_res, hi_res)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator model\n",
    "def build_generator(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    x = MaxPooling2D(padding='same')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(padding='same')(x)\n",
    "    encoded = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = UpSampling2D()(encoded)\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    decoded = Conv2D(3, (3, 3), padding='same', activation='sigmoid')(x)  # Use sigmoid for GAN\n",
    "\n",
    "    return Model(inputs, decoded, name='generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the discriminator model\n",
    "def build_discriminator(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    x = MaxPooling2D(padding='same')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(padding='same')(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs, x, name='discriminator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the GAN model\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    gan_input = Input(shape=(800, 1200, 3))\n",
    "    generated_image = generator(gan_input)\n",
    "    gan_output = discriminator(generated_image)\n",
    "    \n",
    "    gan = Model(gan_input, gan_output)\n",
    "    gan.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n",
    "    \n",
    "    return gan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17141c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the generator, discriminator, and GAN\n",
    "generator = build_generator(input_shape=(800, 1200, 3))\n",
    "discriminator = build_discriminator(input_shape=(800, 1200, 3))\n",
    "gan = build_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the generator\n",
    "generator.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='mean_squared_error')\n",
    "\n",
    "# Compile the discriminator\n",
    "discriminator.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Compile the GAN\n",
    "gan.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the GAN\n",
    "epochs = 10\n",
    "batch_size = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for _ in range(train_samples // batch_size):\n",
    "        low_res, high_res = next(train_generator)\n",
    "        \n",
    "        # Generate high-resolution images from low-resolution input using the generator\n",
    "        generated_high_res = generator.predict(low_res)\n",
    "        \n",
    "        # Train the discriminator on real and generated images\n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "        fake_labels = np.zeros((batch_size, 1))\n",
    "        \n",
    "        real_loss = discriminator.train_on_batch(high_res, real_labels)\n",
    "        fake_loss = discriminator.train_on_batch(generated_high_res, fake_labels)\n",
    "        \n",
    "        # Train the generator via GAN\n",
    "        gan_labels = np.ones((batch_size, 1))\n",
    "        gan_loss = gan.train_on_batch(low_res, gan_labels)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Discriminator Loss: {0.5 * np.add(real_loss, fake_loss)}, GAN Loss: {gan_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fdb210",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate super-resolution images using the trained generator\n",
    "generated_images = generator.predict(validation_low_res_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc8f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "for i in range(5):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].imshow(validation_low_res_images[i])\n",
    "    axs[0].set_title('Low Resolution')\n",
    "    axs[1].imshow(generated_images[i])\n",
    "    axs[1].set_title('Generated High Resolution')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc36229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
